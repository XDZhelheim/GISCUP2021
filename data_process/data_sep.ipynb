{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['20200803.txt',\n",
       " '20200801.txt',\n",
       " '20200802.txt',\n",
       " '20200804.txt',\n",
       " '20200805.txt',\n",
       " '20200806.txt',\n",
       " '20200807.txt',\n",
       " '20200808.txt',\n",
       " '20200809.txt',\n",
       " '20200810.txt',\n",
       " '20200811.txt',\n",
       " '20200812.txt',\n",
       " '20200813.txt',\n",
       " '20200814.txt',\n",
       " '20200815.txt',\n",
       " '20200816.txt',\n",
       " '20200817.txt',\n",
       " '20200818.txt',\n",
       " '20200819.txt',\n",
       " '20200820.txt',\n",
       " '20200821.txt',\n",
       " '20200822.txt',\n",
       " '20200823.txt',\n",
       " '20200824.txt',\n",
       " '20200825.txt',\n",
       " '20200826.txt',\n",
       " '20200827.txt',\n",
       " '20200828.txt',\n",
       " '20200829.txt',\n",
       " '20200830.txt',\n",
       " '20200831.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "PATH = '../data/'\n",
    "filenames = os.listdir(PATH+'/train')[:-3]\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]\n",
      "74328it [00:11, 6285.29it/s] \n",
      "74129it [00:13, 5324.92it/s]\n",
      "172161it [00:37, 4550.16it/s] \n",
      "315756it [01:11, 4419.99it/s] \n",
      "307051it [01:11, 4294.01it/s] \n",
      "308233it [01:08, 4482.09it/s] \n",
      "323961it [01:21, 3952.35it/s]\n",
      "323131it [01:06, 4895.78it/s] \n",
      "291629it [01:12, 4050.18it/s] \n",
      "290647it [01:04, 4507.37it/s] \n",
      "288994it [01:09, 4135.42it/s]\n",
      "297846it [01:01, 4877.36it/s]\n",
      "320924it [01:14, 4298.26it/s] \n",
      "321635it [01:23, 3848.02it/s]\n",
      "316657it [01:05, 4831.80it/s] \n",
      "284095it [01:07, 4228.33it/s] \n",
      "297428it [01:10, 4228.56it/s] \n",
      "285934it [00:59, 4836.05it/s] \n",
      "305369it [01:19, 3853.05it/s]\n",
      "324105it [01:06, 4852.46it/s] \n",
      "342405it [01:28, 3878.30it/s]\n",
      "342610it [01:16, 4484.38it/s] \n",
      "283924it [01:00, 4670.22it/s] \n",
      "329123it [01:18, 4169.22it/s] \n",
      "309158it [01:09, 4446.59it/s] \n",
      "295089it [01:07, 4352.61it/s] \n",
      "314081it [01:14, 4229.68it/s] \n",
      "318662it [01:13, 4332.93it/s]\n",
      "300330it [01:08, 4389.47it/s]\n",
      "291610it [01:01, 4757.29it/s] \n"
     ]
    }
   ],
   "source": [
    "for fn in filenames:\n",
    "    with open(PATH+'train/'+fn, 'r') as f:\n",
    "        head_part = [['order_id','ata','distance','simple_eta','driver_id','slice_id']]\n",
    "        link_part = [['order_id','link_id','link_time','link_ratio','link_current_status','link_arrival_status']]\n",
    "        cross_part = [['order_id','cross id','cross_time']]\n",
    "        for k, parts in tqdm(enumerate(f.readlines())):\n",
    "            line = parts.split(';;')\n",
    "            head = line[0].split(' ')\n",
    "            link = line[1].split(' ')\n",
    "            order_id = head[0]\n",
    "            head_part.append(head)\n",
    "            for segment in link:\n",
    "                tmp = [order_id]\n",
    "                tmp.append(segment.split(':')[0])\n",
    "                tmp.extend(segment.split(':')[1].split(','))\n",
    "                link_part.append(tmp)\n",
    "            if(len(line)>2):\n",
    "                cross = line[2].split(' ')\n",
    "                for light in cross:\n",
    "                    cross_part.append([order_id]+light.split(':'))\n",
    "        with open( PATH+'train/train_head/'+fn[:8]+'.csv','w') as result_file:\n",
    "            wr = csv.writer(result_file)\n",
    "            wr.writerows(head_part)\n",
    "        with open( PATH+'train/train_link/'+fn[:8]+'.csv','w') as result_file:\n",
    "            wr = csv.writer(result_file)\n",
    "            wr.writerows(link_part)\n",
    "        with open( PATH+'train/train_cross/'+fn[:8]+'.csv','w') as result_file:\n",
    "            wr = csv.writer(result_file)\n",
    "            wr.writerows(cross_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "288076it [01:10, 4082.02it/s] \n"
     ]
    }
   ],
   "source": [
    "with open(PATH+'test/20200901_test.txt', 'r') as f:\n",
    "    head_part = [['order_id','ata','distance','simple_eta','driver_id','slice_id']]\n",
    "    link_part = [['order_id','link_id','link_time','link_ratio','link_current_status','link_arrival_status']]\n",
    "    cross_part = [['order_id','cross id','cross_time']]\n",
    "    for k, parts in tqdm(enumerate(f.readlines())):\n",
    "        line = parts.split(';;')\n",
    "        head = line[0].split(' ')\n",
    "        link = line[1].split(' ')\n",
    "        order_id = head[0]\n",
    "        head_part.append(head)\n",
    "        for segment in link:\n",
    "            tmp = [order_id]\n",
    "            tmp.append(segment.split(':')[0])\n",
    "            tmp.extend(segment.split(':')[1].split(','))\n",
    "            link_part.append(tmp)\n",
    "        if(len(line)>2):\n",
    "            cross = line[2].split(' ')\n",
    "            for light in cross:\n",
    "                cross_part.append([order_id]+light.split(':'))\n",
    "    with open( PATH+'test/test_head.csv','w') as result_file:\n",
    "        wr = csv.writer(result_file)\n",
    "        wr.writerows(head_part)\n",
    "    with open( PATH+'test/test_link.csv','w') as result_file:\n",
    "        wr = csv.writer(result_file)\n",
    "        wr.writerows(link_part)\n",
    "    with open( PATH+'test/test_cross.csv','w') as result_file:\n",
    "        wr = csv.writer(result_file)\n",
    "        wr.writerows(cross_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/cseadmin/undergrad1/dz/GISCUP2021/data_process'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dz",
   "language": "python",
   "name": "dz"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}