{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/cseadmin/undergrad1/dz/GISCUP2021/model'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import os, random, csv, datetime, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path=\"../data/\"\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feats(task,head,path,nl,link_feats):\n",
    "########################\n",
    "###head features\n",
    "########################\n",
    "    head['speed'] = head['distance']/head['simple_eta']\n",
    "    head['speed_avg'] = head['slice_id'].map(head.groupby('slice_id')['speed'].mean())\n",
    "    head['speed_std'] = head['slice_id'].map(head.groupby('slice_id')['speed'].std())\n",
    "    head['speed_min'] = head['slice_id'].map(head.groupby('slice_id')['speed'].min())\n",
    "    head['speed_max'] = head['slice_id'].map(head.groupby('slice_id')['speed'].max())\n",
    "    head['volume'] = head['slice_id'].map(head.groupby('slice_id').size())\n",
    "    head['old_driver'] = head['driver_id'].map(head.groupby('driver_id').size())\n",
    "    \n",
    "    head.set_index('order_id',inplace=True)\n",
    "    \n",
    "    path['link_eta'] = path['link_time']*path['link_ratio']\n",
    "    path['cum_time'] = (path.groupby('order_id')['link_eta'].cumsum()/300).astype('int')\n",
    "    link = path[path['cross_flag']==0]\n",
    "    cross = path[path['cross_flag']==1]\n",
    "########################\n",
    "###link features\n",
    "########################\n",
    "    link = link[link['link_time']>0]\n",
    "    link['link_id'] = link['link_id'].astype('int')\n",
    "    link['link_type'] = link['link_id'].map(link_feats['link_label']).fillna(0).astype('int')\n",
    "    link['next_link'] = link['link_id'].map(nl).fillna(0).astype('int')\n",
    "    link['slice_id'] = link['order_id'].map(head['slice_id'])\n",
    "    \n",
    "    gl = link.groupby('order_id')\n",
    "    head['link_no'] = head.index.map(gl.size())\n",
    "    head['link_time_sum'] = head.index.map(gl['link_eta'].sum())\n",
    "    head['link_time_avg'] = head.index.map(gl['link_time'].mean())\n",
    "    head['link_time_std'] = head.index.map(gl['link_time'].std())\n",
    "    head['link_time_max'] = head.index.map(gl['link_time'].max())\n",
    "    head['link_time_min'] = head.index.map(gl['link_time'].min())\n",
    "    \n",
    "    head['time_delay_max'] = head.index.map(gl['cum_time'].max())\n",
    "    head['time_delay_avg'] = head.index.map(gl['cum_time'].mean())\n",
    "    head['time_delay_std'] = head.index.map(gl['cum_time'].std())\n",
    "    \n",
    "    gl = link.groupby(['order_id','link_current_status'])['link_time']\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('current_no_'))\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('current_time_sum_'))\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('current_time_avg_'))\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('current_time_std_'))\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('current_time_max_'))\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('current_time_min_'))\n",
    "\n",
    "    gl = link.groupby(['order_id','next_link'])['link_time']\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('next_no_'))\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('next_time_sum_'))\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('next_time_avg_'))\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('next_time_std_'))\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('next_time_max_'))\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('next_time_min_'))\n",
    "\n",
    "    gl = link.groupby(['order_id','link_type'])['link_time']\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('type_no_'))\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('type_time_sum_'))\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('type_time_avg_'))\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('type_time_std_'))\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('type_time_max_'))\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('type_time_min_'))\n",
    "    \n",
    "#     gl = link.groupby(['order_id','link_arrival_status'])['link_time']\n",
    "#     head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('arrival_no_'))\n",
    "#     head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('arrival_time_sum_'))\n",
    "#     head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('arrival_time_avg_'))\n",
    "#     head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('arrival_time_std_'))\n",
    "#     head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('arrival_time_max_'))\n",
    "#     head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('arrival_time_min_'))\n",
    "\n",
    "########################\n",
    "###cross features\n",
    "########################\n",
    "    gc = cross.groupby('order_id') \n",
    "    head['cross_no'] = head.index.map(gc.size())\n",
    "    head['cross_sum'] = head.index.map(gc['link_time'].sum())\n",
    "    head['cross_avg'] = head.index.map(gc['link_time'].mean())\n",
    "    head['cross_std'] = head.index.map(gc['link_time'].std())\n",
    "    head['cross_max'] = head.index.map(gc['link_time'].max())\n",
    "    head['cross_min'] = head.index.map(gc['link_time'].min())\n",
    "#     head['cross_ratio'] = head['cross_sum']/head['simple_eta']\n",
    "\n",
    "    head = head.fillna(0).reset_index().set_index('slice_id')\n",
    "    gl = link.groupby(['slice_id','link_current_status'])\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('link_status_no_'))\n",
    "    head = head.fillna(0).reset_index()\n",
    "    if(task=='train'):\n",
    "        head['date'] = f[:8]\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pd.read_table(data_path+'nextlinks.txt',sep=' ',names=['link_id','next_link'])\n",
    "network['next_link_no'] = network['next_link'].apply(lambda z: 4 if len(list(z.split(',')))>4 else len(list(z.split(','))))\n",
    "nl = network.set_index('link_id')['next_link_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_feats = pd.read_csv(data_path+'link_feats.csv')\n",
    "link_feats.set_index('Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "31it [30:01, 58.12s/it]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILES = ['202008'+str(i).zfill(2)+'.csv' for i in range(1,32)]\n",
    "for i,f in tqdm(enumerate(TRAIN_FILES)):    \n",
    "    head = pd.read_csv(data_path+'train/train_head/'+f)\n",
    "    path = pd.read_csv(data_path+'train/train_path/'+f)\n",
    "    if(head.shape[0]==0):\n",
    "        continue\n",
    "    head = gen_feats('train',head,path,nl,link_feats)\n",
    "    if(i==0):\n",
    "        head.to_csv(data_path+'train/train.csv',index=False)\n",
    "    else:\n",
    "        head.to_csv(data_path+'train/train.csv',mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = pd.read_csv(data_path+'test/test_head.csv')\n",
    "path = pd.read_csv(data_path+'test/test_path.csv')\n",
    "\n",
    "head = gen_feats('test',head,path,nl,link_feats)\n",
    "head['date'] = '20200901'\n",
    "head.to_csv(data_path+'test/test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dz",
   "language": "python",
   "name": "dz"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}