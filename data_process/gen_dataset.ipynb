{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "train_dir=\"../data/train/\"\r\n",
    "test_dir=\"../data/test/\"\r\n",
    "\r\n",
    "link_dir=\"../data/\"\r\n",
    "\r\n",
    "%pwd"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/cseadmin/undergrad1/dz/GISCUP2021/data_process'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def gen_feats(task, head, path, nl, link_attr, link_time_attr, driver_attr, slice_attr, link_status_attr):\r\n",
    "########################\r\n",
    "###head features\r\n",
    "########################\r\n",
    "    head['speed'] = head['distance']/head['simple_eta']\r\n",
    "    head['speed_avg'] = head['slice_id'].map(head.groupby('slice_id')['speed'].mean())\r\n",
    "    head['speed_std'] = head['slice_id'].map(head.groupby('slice_id')['speed'].std())\r\n",
    "    head['speed_min'] = head['slice_id'].map(head.groupby('slice_id')['speed'].min())\r\n",
    "    head['speed_max'] = head['slice_id'].map(head.groupby('slice_id')['speed'].max())\r\n",
    "    head['volume'] = head['slice_id'].map(head.groupby('slice_id').size())\r\n",
    "    head['old_driver'] = head['driver_id'].map(head.groupby('driver_id').size())\r\n",
    "\r\n",
    "    head['driver_avg'] = head['driver_id'].map(driver_attr['avg'])\r\n",
    "    head['driver_std'] = head['driver_id'].map(driver_attr['std'])\r\n",
    "    head['driver_min'] = head['driver_id'].map(driver_attr['min'])\r\n",
    "    head['driver_max'] = head['driver_id'].map(driver_attr['max'])\r\n",
    "    head['driver_cnt'] = head['driver_id'].map(driver_attr['count'])\r\n",
    "\r\n",
    "    head['slice_avg'] = head['slice_id'].map(slice_attr['avg'])\r\n",
    "    head['slice_std'] = head['slice_id'].map(slice_attr['std'])\r\n",
    "    head['slice_min'] = head['slice_id'].map(slice_attr['min'])\r\n",
    "    head['slice_max'] = head['slice_id'].map(slice_attr['max'])\r\n",
    "    head['slice_count'] = head['slice_id'].map(slice_attr['count'])\r\n",
    "    head['slice_skew'] = head['slice_id'].map(slice_attr['skew'])\r\n",
    "    head['slice_kurt'] = head['slice_id'].map(slice_attr['kurt'])\r\n",
    "    \r\n",
    "    head.set_index('order_id', inplace=True)\r\n",
    "    \r\n",
    "    path['link_eta'] = path['link_time']*path['link_ratio']\r\n",
    "    path['cum_time'] = (path.groupby('order_id')['link_eta'].cumsum()/300).astype('int')\r\n",
    "    link = path[path['cross_flag']==0]\r\n",
    "    cross = path[path['cross_flag']==1]\r\n",
    "########################\r\n",
    "###link features\r\n",
    "########################\r\n",
    "    link = link[link['link_time']>0]\r\n",
    "    link['link_id'] = link['link_id'].astype('int')\r\n",
    "    link['link_type'] = link['link_id'].map(link_attr['link_label']).fillna(0).astype('int')\r\n",
    "    link['next_link'] = link['link_id'].map(nl).fillna(0).astype('int')\r\n",
    "    link['slice_id'] = link['order_id'].map(head['slice_id'])\r\n",
    "\r\n",
    "    link[\"link_time_std\"] = link[\"link_id\"].map(link_time_attr[\"std\"])\r\n",
    "    link[\"link_time_avg\"] = link[\"link_id\"].map(link_time_attr[\"avg\"])\r\n",
    "    link[\"link_time_min\"] = link[\"link_id\"].map(link_time_attr[\"min\"])\r\n",
    "    link[\"link_time_max\"] = link[\"link_id\"].map(link_time_attr[\"max\"])\r\n",
    "    link[\"link_time_count\"] = link[\"link_id\"].map(link_time_attr[\"count\"])\r\n",
    "    link[\"link_time_skew\"] = link[\"link_id\"].map(link_time_attr[\"skew\"])\r\n",
    "    link[\"link_time_kurt\"] = link[\"link_id\"].map(link_time_attr[\"kurt\"])\r\n",
    "    link['link_time_type'] = link['link_id'].map(link_time_attr['label']).fillna(0).astype('int')\r\n",
    "\r\n",
    "    link[\"link_cur_status\"] = link[\"link_id\"].map(link_status_attr[\"current_status\"])\r\n",
    "    link[\"link_arr_status\"] = link[\"link_id\"].map(link_status_attr[\"arrival_status\"])\r\n",
    "    \r\n",
    "    gl = link.groupby('order_id')\r\n",
    "    head['link_no'] = head.index.map(gl.size())\r\n",
    "    head['link_time_sum'] = head.index.map(gl['link_eta'].sum())\r\n",
    "    head['link_time_avg'] = head.index.map(gl['link_time'].mean())\r\n",
    "    head['link_time_std'] = head.index.map(gl['link_time'].std())\r\n",
    "    head['link_time_max'] = head.index.map(gl['link_time'].max())\r\n",
    "    head['link_time_min'] = head.index.map(gl['link_time'].min())\r\n",
    "\r\n",
    "# -----------------------------------------------------------------------------\r\n",
    "    head['link_time_std_sum'] = head.index.map(gl['link_time_std'].sum())\r\n",
    "    head['link_time_std_avg'] = head.index.map(gl['link_time_std'].mean())\r\n",
    "    head['link_time_std_std'] = head.index.map(gl['link_time_std'].std())\r\n",
    "    head['link_time_std_min'] = head.index.map(gl['link_time_std'].min())\r\n",
    "    head['link_time_std_max'] = head.index.map(gl['link_time_std'].max())\r\n",
    "\r\n",
    "    head['link_time_avg_sum'] = head.index.map(gl['link_time_avg'].sum())\r\n",
    "    head['link_time_avg_avg'] = head.index.map(gl['link_time_avg'].mean())\r\n",
    "    head['link_time_avg_std'] = head.index.map(gl['link_time_avg'].std())\r\n",
    "    head['link_time_avg_min'] = head.index.map(gl['link_time_avg'].min())\r\n",
    "    head['link_time_avg_max'] = head.index.map(gl['link_time_avg'].max())\r\n",
    "\r\n",
    "    head['link_time_max_sum'] = head.index.map(gl['link_time_max'].sum())\r\n",
    "    head['link_time_max_avg'] = head.index.map(gl['link_time_max'].mean())\r\n",
    "    head['link_time_max_std'] = head.index.map(gl['link_time_max'].std())\r\n",
    "    head['link_time_max_min'] = head.index.map(gl['link_time_max'].min())\r\n",
    "    head['link_time_max_max'] = head.index.map(gl['link_time_max'].max())\r\n",
    "\r\n",
    "    head['link_time_min_sum'] = head.index.map(gl['link_time_min'].sum())\r\n",
    "    head['link_time_min_avg'] = head.index.map(gl['link_time_min'].mean())\r\n",
    "    head['link_time_min_std'] = head.index.map(gl['link_time_min'].std())\r\n",
    "    head['link_time_min_min'] = head.index.map(gl['link_time_min'].min())\r\n",
    "    head['link_time_min_max'] = head.index.map(gl['link_time_min'].max())\r\n",
    "\r\n",
    "    head['link_time_count_sum'] = head.index.map(gl['link_time_count'].sum())\r\n",
    "    head['link_time_count_avg'] = head.index.map(gl['link_time_count'].mean())\r\n",
    "    head['link_time_count_std'] = head.index.map(gl['link_time_count'].std())\r\n",
    "    head['link_time_count_min'] = head.index.map(gl['link_time_count'].min())\r\n",
    "    head['link_time_count_max'] = head.index.map(gl['link_time_count'].max())\r\n",
    "\r\n",
    "    head['link_time_skew_sum'] = head.index.map(gl['link_time_skew'].sum())\r\n",
    "    head['link_time_skew_avg'] = head.index.map(gl['link_time_skew'].mean())\r\n",
    "    head['link_time_skew_std'] = head.index.map(gl['link_time_skew'].std())\r\n",
    "    head['link_time_skew_min'] = head.index.map(gl['link_time_skew'].min())\r\n",
    "    head['link_time_skew_max'] = head.index.map(gl['link_time_skew'].max())\r\n",
    "\r\n",
    "    head['link_time_kurt_sum'] = head.index.map(gl['link_time_kurt'].sum())\r\n",
    "    head['link_time_kurt_avg'] = head.index.map(gl['link_time_kurt'].mean())\r\n",
    "    head['link_time_kurt_std'] = head.index.map(gl['link_time_kurt'].std())\r\n",
    "    head['link_time_kurt_min'] = head.index.map(gl['link_time_kurt'].min())\r\n",
    "    head['link_time_kurt_max'] = head.index.map(gl['link_time_kurt'].max())\r\n",
    "# -----------------------------------------------------------------------------\r\n",
    "\r\n",
    "    head['link_cur_status_sum'] = head.index.map(gl['link_cur_status'].sum(axis=0))\r\n",
    "    head['link_arr_status_sum'] = head.index.map(gl['link_arr_status'].sum(axis=0))\r\n",
    "    \r\n",
    "    head['time_delay_max'] = head.index.map(gl['cum_time'].max())\r\n",
    "    head['time_delay_avg'] = head.index.map(gl['cum_time'].mean())\r\n",
    "    head['time_delay_std'] = head.index.map(gl['cum_time'].std())\r\n",
    "    \r\n",
    "    gl = link.groupby(['order_id','link_current_status'])['link_time']\r\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('current_no_'))\r\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('current_time_sum_'))\r\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('current_time_avg_'))\r\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('current_time_std_'))\r\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('current_time_max_'))\r\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('current_time_min_'))\r\n",
    "\r\n",
    "    gl = link.groupby(['order_id','next_link'])['link_time']\r\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('next_no_'))\r\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('next_time_sum_'))\r\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('next_time_avg_'))\r\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('next_time_std_'))\r\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('next_time_max_'))\r\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('next_time_min_'))\r\n",
    "\r\n",
    "    gl = link.groupby(['order_id','link_type'])['link_time']\r\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('type_no_'))\r\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('type_time_sum_'))\r\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('type_time_avg_'))\r\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('type_time_std_'))\r\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('type_time_max_'))\r\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('type_time_min_'))\r\n",
    "\r\n",
    "    gl = link.groupby(['order_id','link_time_type'])['link_time']\r\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('time_type_no_'))\r\n",
    "    head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('time_type_time_sum_'))\r\n",
    "    head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('time_type_time_avg_'))\r\n",
    "    head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('time_type_time_std_'))\r\n",
    "    head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('time_type_time_max_'))\r\n",
    "    head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('time_type_time_min_'))\r\n",
    "    \r\n",
    "#     gl = link.groupby(['order_id','link_arrival_status'])['link_time']\r\n",
    "#     head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('arrival_no_'))\r\n",
    "#     head = head.join(gl.sum().unstack(level=-1,fill_value=0).add_prefix('arrival_time_sum_'))\r\n",
    "#     head = head.join(gl.mean().unstack(level=-1,fill_value=0).add_prefix('arrival_time_avg_'))\r\n",
    "#     head = head.join(gl.std().unstack(level=-1,fill_value=0).add_prefix('arrival_time_std_'))\r\n",
    "#     head = head.join(gl.max().unstack(level=-1,fill_value=0).add_prefix('arrival_time_max_'))\r\n",
    "#     head = head.join(gl.min().unstack(level=-1,fill_value=0).add_prefix('arrival_time_min_'))\r\n",
    "\r\n",
    "########################\r\n",
    "###cross features\r\n",
    "########################\r\n",
    "    gc = cross.groupby('order_id') \r\n",
    "    head['cross_no'] = head.index.map(gc.size())\r\n",
    "    head['cross_sum'] = head.index.map(gc['link_time'].sum())\r\n",
    "    head['cross_avg'] = head.index.map(gc['link_time'].mean())\r\n",
    "    head['cross_std'] = head.index.map(gc['link_time'].std())\r\n",
    "    head['cross_max'] = head.index.map(gc['link_time'].max())\r\n",
    "    head['cross_min'] = head.index.map(gc['link_time'].min())\r\n",
    "#     head['cross_ratio'] = head['cross_sum']/head['simple_eta']\r\n",
    "\r\n",
    "    head = head.fillna(0).reset_index().set_index('slice_id')\r\n",
    "    gl = link.groupby(['slice_id','link_current_status'])\r\n",
    "    head = head.join(gl.size().unstack(level=-1,fill_value=0).add_prefix('link_status_no_'))\r\n",
    "    head = head.fillna(0).reset_index()\r\n",
    "\r\n",
    "    if(task=='train'):\r\n",
    "        head['date'] = f[:8]\r\n",
    "    return head"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "network = pd.read_table(link_dir+'nextlinks.txt',sep=' ',names=['link_id','next_link'])\r\n",
    "network['next_link_no'] = network['next_link'].apply(lambda z: 4 if len(list(z.split(',')))>4 else len(list(z.split(','))))\r\n",
    "nl = network.set_index('link_id')['next_link_no']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "link_attr = pd.read_csv(link_dir+'link_attr.csv')\r\n",
    "link_attr.set_index('Unnamed: 0',inplace=True)\r\n",
    "\r\n",
    "link_time_attr = pd.read_csv(link_dir+'link_time_attr.csv')\r\n",
    "link_time_attr.set_index('Unnamed: 0',inplace=True)\r\n",
    "\r\n",
    "driver_attr = pd.read_csv(link_dir+'driver_attr.csv')\r\n",
    "driver_attr.set_index('Unnamed: 0',inplace=True)\r\n",
    "\r\n",
    "slice_attr = pd.read_csv(link_dir+'slice_attr.csv')\r\n",
    "slice_attr.set_index('Unnamed: 0',inplace=True)\r\n",
    "\r\n",
    "link_status_attr = pd.read_csv(link_dir+'link_status_attr.csv')\r\n",
    "link_status_attr.set_index('Unnamed: 0',inplace=True)\r\n",
    "\r\n",
    "link_status_attr.head(10)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of ['Unnamed: 0'] are in the columns\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5a1d44b2f69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlink_status_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'link_status_attr.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlink_status_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlink_status_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cseadmin/anaconda3/envs/dz/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4727\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['Unnamed: 0'] are in the columns\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TRAIN_FILES = ['202008'+str(i).zfill(2)+'.csv' for i in range(1,32)]\r\n",
    "\r\n",
    "for i,f in tqdm(enumerate(TRAIN_FILES)):    \r\n",
    "    head = pd.read_csv(train_dir+'train_head/'+f)\r\n",
    "    path = pd.read_csv(train_dir+'train_path/'+f)\r\n",
    "\r\n",
    "    if(head.shape[0]==0):\r\n",
    "        continue\r\n",
    "    if i==0:\r\n",
    "        train = gen_feats('train', head, path, nl, link_attr, link_time_attr, driver_attr, slice_attr, link_status_attr)\r\n",
    "    else:\r\n",
    "        train = train.append(gen_feats('train', head, path, nl, link_attr, link_time_attr, driver_attr, slice_attr, link_status_attr))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head = pd.read_csv(test_dir+'test_head.csv')\r\n",
    "path = pd.read_csv(test_dir+'test_path.csv')\r\n",
    "\r\n",
    "test = gen_feats('test', head, path, nl, link_attr, link_time_attr, driver_attr, slice_attr, link_status_attr)\r\n",
    "test['date'] = '20200901'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "生成并保存 train set 和 test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "\r\n",
    "train['date'] = pd.to_datetime(train['date'].astype('str'))\r\n",
    "test['date'] = pd.to_datetime(test['date'])\r\n",
    "\r\n",
    "for df in [train, test]:\r\n",
    "    df['day_bias'] = (df['date']-pd.Timestamp(2020,8,1)).dt.days\r\n",
    "    df['weekday'] = df['date'].dt.weekday<5\r\n",
    "    df['cross_no'] = df['cross_no']*(df['cross_sum']>0)\r\n",
    "    df['link_length'] = df['distance']/df['link_no']\r\n",
    "    df['log_distance'] = np.log(df['distance'])\r\n",
    "    df['log_simple_eta'] = np.log(df['simple_eta'])\r\n",
    "    \r\n",
    "    for i in range(5):\r\n",
    "        df['current_no_ratio_'+str(i)] = df['current_no_'+str(i)]/df['link_no']\r\n",
    "        df['current_time_ratio_'+str(i)] = df['current_time_sum_'+str(i)]/(df['simple_eta']-df['cross_sum'])\r\n",
    "        df['next_no_ratio_'+str(i)] = df['next_no_'+str(i)]/df['link_no']\r\n",
    "        df['next_time_ratio_'+str(i)] = df['next_time_sum_'+str(i)]/(df['simple_eta']-df['cross_sum'])\r\n",
    "    for i in range(4):\r\n",
    "        df['type_no_ratio_'+str(i)] = df['type_no_'+str(i)]/df['link_no']\r\n",
    "        df['type_time_ratio_'+str(i)] = df['type_time_sum_'+str(i)]/(df['simple_eta']-df['cross_sum'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3.34 s, sys: 788 ms, total: 4.12 s\n",
      "Wall time: 4.12 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "\r\n",
    "def reduce_mem_usage(df, verbose=True):\r\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\r\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\r\n",
    "    for col in df.columns:\r\n",
    "        col_type = df[col].dtypes\r\n",
    "        if col_type in numerics:\r\n",
    "            c_min = df[col].min()\r\n",
    "            c_max = df[col].max()\r\n",
    "            if str(col_type)[:3] == 'int':\r\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\r\n",
    "                    df[col] = df[col].astype(np.int8)\r\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\r\n",
    "                    df[col] = df[col].astype(np.int16)\r\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\r\n",
    "                    df[col] = df[col].astype(np.int32)\r\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\r\n",
    "                    df[col] = df[col].astype(np.int64)\r\n",
    "            else:\r\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\r\n",
    "                    df[col] = df[col].astype(np.float16)\r\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\r\n",
    "                    df[col] = df[col].astype(np.float32)\r\n",
    "                else:\r\n",
    "                    df[col] = df[col].astype(np.float64)\r\n",
    "\r\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\r\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\r\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\r\n",
    "\r\n",
    "    return df\r\n",
    "    \r\n",
    "train = reduce_mem_usage(train)\r\n",
    "test = reduce_mem_usage(test)\r\n",
    "print(train.info())\r\n",
    "print(test.info())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory usage after optimization is: 3192.84 MB\n",
      "Decreased by 73.3%\n",
      "Memory usage after optimization is: 101.65 MB\n",
      "Decreased by 74.3%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8651005 entries, 0 to 291609\n",
      "Columns: 181 entries, slice_id to type_time_ratio_3\n",
      "dtypes: bool(1), datetime64[ns](1), float16(142), float32(5), int16(22), int32(4), int8(6)\n",
      "memory usage: 3.1 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288076 entries, 0 to 288075\n",
      "Columns: 181 entries, slice_id to type_time_ratio_3\n",
      "dtypes: bool(1), datetime64[ns](1), float16(147), float32(3), int16(17), int32(3), int8(9)\n",
      "memory usage: 101.7 MB\n",
      "None\n",
      "CPU times: user 38.9 s, sys: 13.8 s, total: 52.6 s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train.to_pickle(train_dir+'train.pkl')\r\n",
    "test.to_pickle(test_dir+'test.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dz",
   "language": "python",
   "name": "dz"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}